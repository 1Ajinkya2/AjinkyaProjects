{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlhM2U9aaqOIALdnTGf98c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1Ajinkya2/AjinkyaProjects/blob/main/Ayurveda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inL6lIIVsw2s",
        "outputId": "9ca5e326-b07d-4f2e-a15b-25f28e6134eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.30 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.31)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.40)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.40)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.37->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install InstructorEmbedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tti3WXvEtzYV",
        "outputId": "a7cea11e-f049-429a-c448-791630bf5c63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: InstructorEmbedding in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain InstructorEmbedding pypdf tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcnrUDR8uGSH",
        "outputId": "d03b4c4c-a273-4d6a-da13-0535804c3391"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.14)\n",
            "Requirement already satisfied: InstructorEmbedding in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Collecting pypdf\n",
            "  Using cached pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
            "Collecting tiktoken\n",
            "  Using cached tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.30 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.31)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.40)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.40)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.37->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Installing collected packages: pypdf, tiktoken\n",
            "Successfully installed pypdf-4.1.0 tiktoken-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpVZWNWevdhp",
        "outputId": "215fda2d-ae49-432d-f6f1-c96fb03591d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.4.24)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.6.4)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.110.1)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.29.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.10.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.17.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.24.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.2)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.2)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.62.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.2)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.4)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (29.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.24.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.45b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.45b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.45b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.6)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.18.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -v \"sentence-transformers==2.2.2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frCAIpDfvlyT",
        "outputId": "c2f07b14-8783-44d4-ac88-0f9182436eb2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Collecting sentence-transformers==2.2.2\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Running command python setup.py egg_info\n",
            "  /usr/local/lib/python3.10/dist-packages/setuptools/dist.py:755: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
            "  !!\n",
            "\n",
            "          ********************************************************************************\n",
            "          Usage of dash-separated 'description-file' will not be supported in future\n",
            "          versions. Please use the underscore name 'description_file' instead.\n",
            "\n",
            "          This deprecation is overdue, please update your project and remove deprecated\n",
            "          calls to avoid build errors in the future.\n",
            "\n",
            "          See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
            "          ********************************************************************************\n",
            "\n",
            "  !!\n",
            "    opt = self.warn_dash_deprecation(opt, section)\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-srlvxx_2/sentence_transformers.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-srlvxx_2/sentence_transformers.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-srlvxx_2/sentence_transformers.egg-info/dependency_links.txt\n",
            "  writing requirements to /tmp/pip-pip-egg-info-srlvxx_2/sentence_transformers.egg-info/requires.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-srlvxx_2/sentence_transformers.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-srlvxx_2/sentence_transformers.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-pip-egg-info-srlvxx_2/sentence_transformers.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE'\n",
            "  adding license file 'NOTICE.txt'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-srlvxx_2/sentence_transformers.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.17.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.2.2) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers==2.2.2) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Running command python setup.py bdist_wheel\n",
            "  /usr/local/lib/python3.10/dist-packages/setuptools/dist.py:755: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
            "  !!\n",
            "\n",
            "          ********************************************************************************\n",
            "          Usage of dash-separated 'description-file' will not be supported in future\n",
            "          versions. Please use the underscore name 'description_file' instead.\n",
            "\n",
            "          This deprecation is overdue, please update your project and remove deprecated\n",
            "          calls to avoid build errors in the future.\n",
            "\n",
            "          See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
            "          ********************************************************************************\n",
            "\n",
            "  !!\n",
            "    opt = self.warn_dash_deprecation(opt, section)\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib\n",
            "  creating build/lib/sentence_transformers\n",
            "  copying sentence_transformers/LoggingHandler.py -> build/lib/sentence_transformers\n",
            "  copying sentence_transformers/__init__.py -> build/lib/sentence_transformers\n",
            "  copying sentence_transformers/util.py -> build/lib/sentence_transformers\n",
            "  copying sentence_transformers/SentenceTransformer.py -> build/lib/sentence_transformers\n",
            "  copying sentence_transformers/model_card_templates.py -> build/lib/sentence_transformers\n",
            "  creating build/lib/sentence_transformers/models\n",
            "  copying sentence_transformers/models/CNN.py -> build/lib/sentence_transformers/models\n",
            "  copying sentence_transformers/models/CLIPModel.py -> build/lib/sentence_transformers/models\n",
            "  copying sentence_transformers/models/Dropout.py -> build/lib/sentence_transformers/models\n",
            "  copying sentence_transformers/models/Normalize.py -> build/lib/sentence_transformers/models\n",
            "  copying sentence_transformers/models/Pooling.py -> build/lib/sentence_transformers/models\n",
            "  copying sentence_transformers/models/__init__.py -> build/lib/sentence_transformers/models\n",
            "  copying sentence_transformers/models/Dense.py -> build/lib/sentence_transformers/models\n",
            "  copying sentence_transformers/models/LayerNorm.py -> build/lib/sentence_transformers/models\n",
            "  copying sentence_transformers/models/WordWeights.py -> build/lib/sentence_transformers/models\n",
            "  copying sentence_transformers/models/BoW.py -> build/lib/sentence_transformers/models\n",
            "  copying sentence_transformers/models/Transformer.py -> build/lib/sentence_transformers/models\n",
            "  copying sentence_transformers/models/WeightedLayerPooling.py -> build/lib/sentence_transformers/models\n",
            "  copying sentence_transformers/models/Asym.py -> build/lib/sentence_transformers/models\n",
            "  copying sentence_transformers/models/WordEmbeddings.py -> build/lib/sentence_transformers/models\n",
            "  copying sentence_transformers/models/LSTM.py -> build/lib/sentence_transformers/models\n",
            "  creating build/lib/sentence_transformers/evaluation\n",
            "  copying sentence_transformers/evaluation/LabelAccuracyEvaluator.py -> build/lib/sentence_transformers/evaluation\n",
            "  copying sentence_transformers/evaluation/ParaphraseMiningEvaluator.py -> build/lib/sentence_transformers/evaluation\n",
            "  copying sentence_transformers/evaluation/SimilarityFunction.py -> build/lib/sentence_transformers/evaluation\n",
            "  copying sentence_transformers/evaluation/InformationRetrievalEvaluator.py -> build/lib/sentence_transformers/evaluation\n",
            "  copying sentence_transformers/evaluation/MSEEvaluatorFromDataFrame.py -> build/lib/sentence_transformers/evaluation\n",
            "  copying sentence_transformers/evaluation/BinaryClassificationEvaluator.py -> build/lib/sentence_transformers/evaluation\n",
            "  copying sentence_transformers/evaluation/SequentialEvaluator.py -> build/lib/sentence_transformers/evaluation\n",
            "  copying sentence_transformers/evaluation/SentenceEvaluator.py -> build/lib/sentence_transformers/evaluation\n",
            "  copying sentence_transformers/evaluation/TranslationEvaluator.py -> build/lib/sentence_transformers/evaluation\n",
            "  copying sentence_transformers/evaluation/__init__.py -> build/lib/sentence_transformers/evaluation\n",
            "  copying sentence_transformers/evaluation/RerankingEvaluator.py -> build/lib/sentence_transformers/evaluation\n",
            "  copying sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py -> build/lib/sentence_transformers/evaluation\n",
            "  copying sentence_transformers/evaluation/MSEEvaluator.py -> build/lib/sentence_transformers/evaluation\n",
            "  copying sentence_transformers/evaluation/TripletEvaluator.py -> build/lib/sentence_transformers/evaluation\n",
            "  creating build/lib/sentence_transformers/losses\n",
            "  copying sentence_transformers/losses/BatchHardSoftMarginTripletLoss.py -> build/lib/sentence_transformers/losses\n",
            "  copying sentence_transformers/losses/MultipleNegativesRankingLoss.py -> build/lib/sentence_transformers/losses\n",
            "  copying sentence_transformers/losses/ContrastiveTensionLoss.py -> build/lib/sentence_transformers/losses\n",
            "  copying sentence_transformers/losses/MarginMSELoss.py -> build/lib/sentence_transformers/losses\n",
            "  copying sentence_transformers/losses/BatchAllTripletLoss.py -> build/lib/sentence_transformers/losses\n",
            "  copying sentence_transformers/losses/MSELoss.py -> build/lib/sentence_transformers/losses\n",
            "  copying sentence_transformers/losses/DenoisingAutoEncoderLoss.py -> build/lib/sentence_transformers/losses\n",
            "  copying sentence_transformers/losses/ContrastiveLoss.py -> build/lib/sentence_transformers/losses\n",
            "  copying sentence_transformers/losses/BatchSemiHardTripletLoss.py -> build/lib/sentence_transformers/losses\n",
            "  copying sentence_transformers/losses/CosineSimilarityLoss.py -> build/lib/sentence_transformers/losses\n",
            "  copying sentence_transformers/losses/SoftmaxLoss.py -> build/lib/sentence_transformers/losses\n",
            "  copying sentence_transformers/losses/OnlineContrastiveLoss.py -> build/lib/sentence_transformers/losses\n",
            "  copying sentence_transformers/losses/MultipleNegativesSymmetricRankingLoss.py -> build/lib/sentence_transformers/losses\n",
            "  copying sentence_transformers/losses/BatchHardTripletLoss.py -> build/lib/sentence_transformers/losses\n",
            "  copying sentence_transformers/losses/TripletLoss.py -> build/lib/sentence_transformers/losses\n",
            "  copying sentence_transformers/losses/__init__.py -> build/lib/sentence_transformers/losses\n",
            "  copying sentence_transformers/losses/MegaBatchMarginLoss.py -> build/lib/sentence_transformers/losses\n",
            "  creating build/lib/sentence_transformers/readers\n",
            "  copying sentence_transformers/readers/TripletReader.py -> build/lib/sentence_transformers/readers\n",
            "  copying sentence_transformers/readers/PairedFilesReader.py -> build/lib/sentence_transformers/readers\n",
            "  copying sentence_transformers/readers/LabelSentenceReader.py -> build/lib/sentence_transformers/readers\n",
            "  copying sentence_transformers/readers/InputExample.py -> build/lib/sentence_transformers/readers\n",
            "  copying sentence_transformers/readers/__init__.py -> build/lib/sentence_transformers/readers\n",
            "  copying sentence_transformers/readers/STSDataReader.py -> build/lib/sentence_transformers/readers\n",
            "  copying sentence_transformers/readers/NLIDataReader.py -> build/lib/sentence_transformers/readers\n",
            "  creating build/lib/sentence_transformers/datasets\n",
            "  copying sentence_transformers/datasets/DenoisingAutoEncoderDataset.py -> build/lib/sentence_transformers/datasets\n",
            "  copying sentence_transformers/datasets/SentenceLabelDataset.py -> build/lib/sentence_transformers/datasets\n",
            "  copying sentence_transformers/datasets/__init__.py -> build/lib/sentence_transformers/datasets\n",
            "  copying sentence_transformers/datasets/SentencesDataset.py -> build/lib/sentence_transformers/datasets\n",
            "  copying sentence_transformers/datasets/ParallelSentencesDataset.py -> build/lib/sentence_transformers/datasets\n",
            "  copying sentence_transformers/datasets/NoDuplicatesDataLoader.py -> build/lib/sentence_transformers/datasets\n",
            "  creating build/lib/sentence_transformers/cross_encoder\n",
            "  copying sentence_transformers/cross_encoder/__init__.py -> build/lib/sentence_transformers/cross_encoder\n",
            "  copying sentence_transformers/cross_encoder/CrossEncoder.py -> build/lib/sentence_transformers/cross_encoder\n",
            "  creating build/lib/sentence_transformers/models/tokenizer\n",
            "  copying sentence_transformers/models/tokenizer/WordTokenizer.py -> build/lib/sentence_transformers/models/tokenizer\n",
            "  copying sentence_transformers/models/tokenizer/__init__.py -> build/lib/sentence_transformers/models/tokenizer\n",
            "  copying sentence_transformers/models/tokenizer/PhraseTokenizer.py -> build/lib/sentence_transformers/models/tokenizer\n",
            "  copying sentence_transformers/models/tokenizer/WhitespaceTokenizer.py -> build/lib/sentence_transformers/models/tokenizer\n",
            "  creating build/lib/sentence_transformers/cross_encoder/evaluation\n",
            "  copying sentence_transformers/cross_encoder/evaluation/CECorrelationEvaluator.py -> build/lib/sentence_transformers/cross_encoder/evaluation\n",
            "  copying sentence_transformers/cross_encoder/evaluation/CESoftmaxAccuracyEvaluator.py -> build/lib/sentence_transformers/cross_encoder/evaluation\n",
            "  copying sentence_transformers/cross_encoder/evaluation/CERerankingEvaluator.py -> build/lib/sentence_transformers/cross_encoder/evaluation\n",
            "  copying sentence_transformers/cross_encoder/evaluation/CEBinaryClassificationEvaluator.py -> build/lib/sentence_transformers/cross_encoder/evaluation\n",
            "  copying sentence_transformers/cross_encoder/evaluation/__init__.py -> build/lib/sentence_transformers/cross_encoder/evaluation\n",
            "  copying sentence_transformers/cross_encoder/evaluation/CEBinaryAccuracyEvaluator.py -> build/lib/sentence_transformers/cross_encoder/evaluation\n",
            "  /usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "  !!\n",
            "\n",
            "          ********************************************************************************\n",
            "          Please avoid running ``setup.py`` directly.\n",
            "          Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "          other standards-based tools.\n",
            "\n",
            "          See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "          ********************************************************************************\n",
            "\n",
            "  !!\n",
            "    self.initialize_options()\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/sentence_transformers\n",
            "  copying build/lib/sentence_transformers/LoggingHandler.py -> build/bdist.linux-x86_64/wheel/sentence_transformers\n",
            "  creating build/bdist.linux-x86_64/wheel/sentence_transformers/models\n",
            "  copying build/lib/sentence_transformers/models/CNN.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models\n",
            "  copying build/lib/sentence_transformers/models/CLIPModel.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models\n",
            "  copying build/lib/sentence_transformers/models/Dropout.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models\n",
            "  copying build/lib/sentence_transformers/models/Normalize.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models\n",
            "  copying build/lib/sentence_transformers/models/Pooling.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models\n",
            "  copying build/lib/sentence_transformers/models/__init__.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models\n",
            "  copying build/lib/sentence_transformers/models/Dense.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models\n",
            "  copying build/lib/sentence_transformers/models/LayerNorm.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models\n",
            "  creating build/bdist.linux-x86_64/wheel/sentence_transformers/models/tokenizer\n",
            "  copying build/lib/sentence_transformers/models/tokenizer/WordTokenizer.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models/tokenizer\n",
            "  copying build/lib/sentence_transformers/models/tokenizer/__init__.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models/tokenizer\n",
            "  copying build/lib/sentence_transformers/models/tokenizer/PhraseTokenizer.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models/tokenizer\n",
            "  copying build/lib/sentence_transformers/models/tokenizer/WhitespaceTokenizer.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models/tokenizer\n",
            "  copying build/lib/sentence_transformers/models/WordWeights.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models\n",
            "  copying build/lib/sentence_transformers/models/BoW.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models\n",
            "  copying build/lib/sentence_transformers/models/Transformer.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models\n",
            "  copying build/lib/sentence_transformers/models/WeightedLayerPooling.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models\n",
            "  copying build/lib/sentence_transformers/models/Asym.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models\n",
            "  copying build/lib/sentence_transformers/models/WordEmbeddings.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models\n",
            "  copying build/lib/sentence_transformers/models/LSTM.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/models\n",
            "  creating build/bdist.linux-x86_64/wheel/sentence_transformers/evaluation\n",
            "  copying build/lib/sentence_transformers/evaluation/LabelAccuracyEvaluator.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/evaluation\n",
            "  copying build/lib/sentence_transformers/evaluation/ParaphraseMiningEvaluator.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/evaluation\n",
            "  copying build/lib/sentence_transformers/evaluation/SimilarityFunction.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/evaluation\n",
            "  copying build/lib/sentence_transformers/evaluation/InformationRetrievalEvaluator.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/evaluation\n",
            "  copying build/lib/sentence_transformers/evaluation/MSEEvaluatorFromDataFrame.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/evaluation\n",
            "  copying build/lib/sentence_transformers/evaluation/BinaryClassificationEvaluator.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/evaluation\n",
            "  copying build/lib/sentence_transformers/evaluation/SequentialEvaluator.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/evaluation\n",
            "  copying build/lib/sentence_transformers/evaluation/SentenceEvaluator.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/evaluation\n",
            "  copying build/lib/sentence_transformers/evaluation/TranslationEvaluator.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/evaluation\n",
            "  copying build/lib/sentence_transformers/evaluation/__init__.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/evaluation\n",
            "  copying build/lib/sentence_transformers/evaluation/RerankingEvaluator.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/evaluation\n",
            "  copying build/lib/sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/evaluation\n",
            "  copying build/lib/sentence_transformers/evaluation/MSEEvaluator.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/evaluation\n",
            "  copying build/lib/sentence_transformers/evaluation/TripletEvaluator.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/evaluation\n",
            "  creating build/bdist.linux-x86_64/wheel/sentence_transformers/losses\n",
            "  copying build/lib/sentence_transformers/losses/BatchHardSoftMarginTripletLoss.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/losses\n",
            "  copying build/lib/sentence_transformers/losses/MultipleNegativesRankingLoss.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/losses\n",
            "  copying build/lib/sentence_transformers/losses/ContrastiveTensionLoss.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/losses\n",
            "  copying build/lib/sentence_transformers/losses/MarginMSELoss.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/losses\n",
            "  copying build/lib/sentence_transformers/losses/BatchAllTripletLoss.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/losses\n",
            "  copying build/lib/sentence_transformers/losses/MSELoss.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/losses\n",
            "  copying build/lib/sentence_transformers/losses/DenoisingAutoEncoderLoss.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/losses\n",
            "  copying build/lib/sentence_transformers/losses/ContrastiveLoss.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/losses\n",
            "  copying build/lib/sentence_transformers/losses/BatchSemiHardTripletLoss.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/losses\n",
            "  copying build/lib/sentence_transformers/losses/CosineSimilarityLoss.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/losses\n",
            "  copying build/lib/sentence_transformers/losses/SoftmaxLoss.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/losses\n",
            "  copying build/lib/sentence_transformers/losses/OnlineContrastiveLoss.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/losses\n",
            "  copying build/lib/sentence_transformers/losses/MultipleNegativesSymmetricRankingLoss.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/losses\n",
            "  copying build/lib/sentence_transformers/losses/BatchHardTripletLoss.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/losses\n",
            "  copying build/lib/sentence_transformers/losses/TripletLoss.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/losses\n",
            "  copying build/lib/sentence_transformers/losses/__init__.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/losses\n",
            "  copying build/lib/sentence_transformers/losses/MegaBatchMarginLoss.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/losses\n",
            "  creating build/bdist.linux-x86_64/wheel/sentence_transformers/readers\n",
            "  copying build/lib/sentence_transformers/readers/TripletReader.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/readers\n",
            "  copying build/lib/sentence_transformers/readers/PairedFilesReader.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/readers\n",
            "  copying build/lib/sentence_transformers/readers/LabelSentenceReader.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/readers\n",
            "  copying build/lib/sentence_transformers/readers/InputExample.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/readers\n",
            "  copying build/lib/sentence_transformers/readers/__init__.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/readers\n",
            "  copying build/lib/sentence_transformers/readers/STSDataReader.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/readers\n",
            "  copying build/lib/sentence_transformers/readers/NLIDataReader.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/readers\n",
            "  copying build/lib/sentence_transformers/__init__.py -> build/bdist.linux-x86_64/wheel/sentence_transformers\n",
            "  copying build/lib/sentence_transformers/util.py -> build/bdist.linux-x86_64/wheel/sentence_transformers\n",
            "  creating build/bdist.linux-x86_64/wheel/sentence_transformers/datasets\n",
            "  copying build/lib/sentence_transformers/datasets/DenoisingAutoEncoderDataset.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/datasets\n",
            "  copying build/lib/sentence_transformers/datasets/SentenceLabelDataset.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/datasets\n",
            "  copying build/lib/sentence_transformers/datasets/__init__.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/datasets\n",
            "  copying build/lib/sentence_transformers/datasets/SentencesDataset.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/datasets\n",
            "  copying build/lib/sentence_transformers/datasets/ParallelSentencesDataset.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/datasets\n",
            "  copying build/lib/sentence_transformers/datasets/NoDuplicatesDataLoader.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/datasets\n",
            "  creating build/bdist.linux-x86_64/wheel/sentence_transformers/cross_encoder\n",
            "  creating build/bdist.linux-x86_64/wheel/sentence_transformers/cross_encoder/evaluation\n",
            "  copying build/lib/sentence_transformers/cross_encoder/evaluation/CECorrelationEvaluator.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/cross_encoder/evaluation\n",
            "  copying build/lib/sentence_transformers/cross_encoder/evaluation/CESoftmaxAccuracyEvaluator.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/cross_encoder/evaluation\n",
            "  copying build/lib/sentence_transformers/cross_encoder/evaluation/CERerankingEvaluator.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/cross_encoder/evaluation\n",
            "  copying build/lib/sentence_transformers/cross_encoder/evaluation/CEBinaryClassificationEvaluator.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/cross_encoder/evaluation\n",
            "  copying build/lib/sentence_transformers/cross_encoder/evaluation/__init__.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/cross_encoder/evaluation\n",
            "  copying build/lib/sentence_transformers/cross_encoder/evaluation/CEBinaryAccuracyEvaluator.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/cross_encoder/evaluation\n",
            "  copying build/lib/sentence_transformers/cross_encoder/__init__.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/cross_encoder\n",
            "  copying build/lib/sentence_transformers/cross_encoder/CrossEncoder.py -> build/bdist.linux-x86_64/wheel/sentence_transformers/cross_encoder\n",
            "  copying build/lib/sentence_transformers/SentenceTransformer.py -> build/bdist.linux-x86_64/wheel/sentence_transformers\n",
            "  copying build/lib/sentence_transformers/model_card_templates.py -> build/bdist.linux-x86_64/wheel/sentence_transformers\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing sentence_transformers.egg-info/PKG-INFO\n",
            "  writing dependency_links to sentence_transformers.egg-info/dependency_links.txt\n",
            "  writing requirements to sentence_transformers.egg-info/requires.txt\n",
            "  writing top-level names to sentence_transformers.egg-info/top_level.txt\n",
            "  reading manifest file 'sentence_transformers.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE'\n",
            "  adding license file 'NOTICE.txt'\n",
            "  writing manifest file 'sentence_transformers.egg-info/SOURCES.txt'\n",
            "  Copying sentence_transformers.egg-info to build/bdist.linux-x86_64/wheel/sentence_transformers-2.2.2-py3.10.egg-info\n",
            "  running install_scripts\n",
            "  creating build/bdist.linux-x86_64/wheel/sentence_transformers-2.2.2.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-fv3_qv7z/sentence_transformers-2.2.2-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'sentence_transformers/LoggingHandler.py'\n",
            "  adding 'sentence_transformers/SentenceTransformer.py'\n",
            "  adding 'sentence_transformers/__init__.py'\n",
            "  adding 'sentence_transformers/model_card_templates.py'\n",
            "  adding 'sentence_transformers/util.py'\n",
            "  adding 'sentence_transformers/cross_encoder/CrossEncoder.py'\n",
            "  adding 'sentence_transformers/cross_encoder/__init__.py'\n",
            "  adding 'sentence_transformers/cross_encoder/evaluation/CEBinaryAccuracyEvaluator.py'\n",
            "  adding 'sentence_transformers/cross_encoder/evaluation/CEBinaryClassificationEvaluator.py'\n",
            "  adding 'sentence_transformers/cross_encoder/evaluation/CECorrelationEvaluator.py'\n",
            "  adding 'sentence_transformers/cross_encoder/evaluation/CERerankingEvaluator.py'\n",
            "  adding 'sentence_transformers/cross_encoder/evaluation/CESoftmaxAccuracyEvaluator.py'\n",
            "  adding 'sentence_transformers/cross_encoder/evaluation/__init__.py'\n",
            "  adding 'sentence_transformers/datasets/DenoisingAutoEncoderDataset.py'\n",
            "  adding 'sentence_transformers/datasets/NoDuplicatesDataLoader.py'\n",
            "  adding 'sentence_transformers/datasets/ParallelSentencesDataset.py'\n",
            "  adding 'sentence_transformers/datasets/SentenceLabelDataset.py'\n",
            "  adding 'sentence_transformers/datasets/SentencesDataset.py'\n",
            "  adding 'sentence_transformers/datasets/__init__.py'\n",
            "  adding 'sentence_transformers/evaluation/BinaryClassificationEvaluator.py'\n",
            "  adding 'sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py'\n",
            "  adding 'sentence_transformers/evaluation/InformationRetrievalEvaluator.py'\n",
            "  adding 'sentence_transformers/evaluation/LabelAccuracyEvaluator.py'\n",
            "  adding 'sentence_transformers/evaluation/MSEEvaluator.py'\n",
            "  adding 'sentence_transformers/evaluation/MSEEvaluatorFromDataFrame.py'\n",
            "  adding 'sentence_transformers/evaluation/ParaphraseMiningEvaluator.py'\n",
            "  adding 'sentence_transformers/evaluation/RerankingEvaluator.py'\n",
            "  adding 'sentence_transformers/evaluation/SentenceEvaluator.py'\n",
            "  adding 'sentence_transformers/evaluation/SequentialEvaluator.py'\n",
            "  adding 'sentence_transformers/evaluation/SimilarityFunction.py'\n",
            "  adding 'sentence_transformers/evaluation/TranslationEvaluator.py'\n",
            "  adding 'sentence_transformers/evaluation/TripletEvaluator.py'\n",
            "  adding 'sentence_transformers/evaluation/__init__.py'\n",
            "  adding 'sentence_transformers/losses/BatchAllTripletLoss.py'\n",
            "  adding 'sentence_transformers/losses/BatchHardSoftMarginTripletLoss.py'\n",
            "  adding 'sentence_transformers/losses/BatchHardTripletLoss.py'\n",
            "  adding 'sentence_transformers/losses/BatchSemiHardTripletLoss.py'\n",
            "  adding 'sentence_transformers/losses/ContrastiveLoss.py'\n",
            "  adding 'sentence_transformers/losses/ContrastiveTensionLoss.py'\n",
            "  adding 'sentence_transformers/losses/CosineSimilarityLoss.py'\n",
            "  adding 'sentence_transformers/losses/DenoisingAutoEncoderLoss.py'\n",
            "  adding 'sentence_transformers/losses/MSELoss.py'\n",
            "  adding 'sentence_transformers/losses/MarginMSELoss.py'\n",
            "  adding 'sentence_transformers/losses/MegaBatchMarginLoss.py'\n",
            "  adding 'sentence_transformers/losses/MultipleNegativesRankingLoss.py'\n",
            "  adding 'sentence_transformers/losses/MultipleNegativesSymmetricRankingLoss.py'\n",
            "  adding 'sentence_transformers/losses/OnlineContrastiveLoss.py'\n",
            "  adding 'sentence_transformers/losses/SoftmaxLoss.py'\n",
            "  adding 'sentence_transformers/losses/TripletLoss.py'\n",
            "  adding 'sentence_transformers/losses/__init__.py'\n",
            "  adding 'sentence_transformers/models/Asym.py'\n",
            "  adding 'sentence_transformers/models/BoW.py'\n",
            "  adding 'sentence_transformers/models/CLIPModel.py'\n",
            "  adding 'sentence_transformers/models/CNN.py'\n",
            "  adding 'sentence_transformers/models/Dense.py'\n",
            "  adding 'sentence_transformers/models/Dropout.py'\n",
            "  adding 'sentence_transformers/models/LSTM.py'\n",
            "  adding 'sentence_transformers/models/LayerNorm.py'\n",
            "  adding 'sentence_transformers/models/Normalize.py'\n",
            "  adding 'sentence_transformers/models/Pooling.py'\n",
            "  adding 'sentence_transformers/models/Transformer.py'\n",
            "  adding 'sentence_transformers/models/WeightedLayerPooling.py'\n",
            "  adding 'sentence_transformers/models/WordEmbeddings.py'\n",
            "  adding 'sentence_transformers/models/WordWeights.py'\n",
            "  adding 'sentence_transformers/models/__init__.py'\n",
            "  adding 'sentence_transformers/models/tokenizer/PhraseTokenizer.py'\n",
            "  adding 'sentence_transformers/models/tokenizer/WhitespaceTokenizer.py'\n",
            "  adding 'sentence_transformers/models/tokenizer/WordTokenizer.py'\n",
            "  adding 'sentence_transformers/models/tokenizer/__init__.py'\n",
            "  adding 'sentence_transformers/readers/InputExample.py'\n",
            "  adding 'sentence_transformers/readers/LabelSentenceReader.py'\n",
            "  adding 'sentence_transformers/readers/NLIDataReader.py'\n",
            "  adding 'sentence_transformers/readers/PairedFilesReader.py'\n",
            "  adding 'sentence_transformers/readers/STSDataReader.py'\n",
            "  adding 'sentence_transformers/readers/TripletReader.py'\n",
            "  adding 'sentence_transformers/readers/__init__.py'\n",
            "  adding 'sentence_transformers-2.2.2.dist-info/LICENSE'\n",
            "  adding 'sentence_transformers-2.2.2.dist-info/METADATA'\n",
            "  adding 'sentence_transformers-2.2.2.dist-info/NOTICE.txt'\n",
            "  adding 'sentence_transformers-2.2.2.dist-info/WHEEL'\n",
            "  adding 'sentence_transformers-2.2.2.dist-info/top_level.txt'\n",
            "  adding 'sentence_transformers-2.2.2.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125924 sha256=a2ed3e8b67d8c9b75c83d0fd38f8243a1ab2306e1674574be222ad25dca4d621\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sentence-transformers-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIrdnKs7wPIN",
        "outputId": "93685898-2901-4ca9-ee44-2457bca5902d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "pdf_folder_path = f'{root_dir}/Dataset'\n",
        "os.listdir(pdf_folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5gm1lkTwfy6",
        "outputId": "a10af20b-3765-44d8-b963-80e21ad4c50c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['32ba6145-a5a3-4e43-9f30-bc21f673b1a1']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
        "db = Chroma(persist_directory=\"pdf_folder_path\", embedding_function=instructor_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZRbY00Mw0h4",
        "outputId": "d567edfb-251b-4ad3-90d2-cf4bafba7d8f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "UYsNjAOXxoLr",
        "outputId": "fc499c61-8c2a-4c38-958a-6d5b679a3ab7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-18-761e0f1ff21e>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-761e0f1ff21e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install langchain-google-genai\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycDdusFvyJMq",
        "outputId": "d14161c2-9563-45ff-d697-dc38c96586b2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: google-generativeai<0.5.0,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.1.40)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (2.11.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (2.6.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (4.10.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.4.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (1.23.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (0.1.40)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (23.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (8.2.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain-google-genai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai) (3.10.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (2.16.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (1.63.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (1.62.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from InstructorEmbedding import INSTRUCTOR\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "custom_prompt_template = \"\"\"You are an great ancient sanskrit ayurvedic scholar you the give the remedies to diseases keep your talking tone ancient and Use the following pieces of context to answer a question as much detailed as possible also start your response with some nice greeting and also in the end at the note to consult to the doctor . If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(template=custom_prompt_template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  \\n')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
        "                                   temperature=0.8,google_api_key=\"AIzaSyAWLDPjFGdS6aZgpjVN3F0cIzLgxNREeGg\",convert_system_message_to_human=True)\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db.as_retriever(),\n",
        "    chain_type_kwargs={\"prompt\": prompt}\n",
        ")\n",
        "response=qa_chain.run('Suggest me ayurvedic remedies for fever')\n",
        "to_markdown(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "Lx0N4i7by-Zl",
        "outputId": "124ba1c7-182e-4452-941a-7164b5a36a7b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Greetings, dear seeker of ancient wisdom.\n> \n> As an Ayurvedic scholar, I am well-versed in the ancient texts that hold the secrets to healing through natural remedies.\n> \n> For the ailment of fever, Ayurveda offers the following remedies:\n> \n> * **Triphala:** This powerful herbal concoction, composed of three fruits (amla, bibhitaki, and haritaki), has antipyretic properties that can help reduce fever.\n> * **Guduchi:** Also known as Giloy, this herb is renowned for its anti-inflammatory and antipyretic effects, making it effective in treating fever.\n> * **Neem:** The leaves of this tree possess antibacterial, antiviral, and anti-inflammatory properties that can help combat the infection causing fever.\n> * **Ginger:** This pungent spice has diaphoretic properties, meaning it can induce sweating, which can help reduce body temperature and break a fever.\n> * **Turmeric:** Curcumin, the active compound in turmeric, has anti-inflammatory and antioxidant properties that can help reduce fever and boost immunity.\n> \n> It's important to note that these remedies are general guidelines. For a personalized treatment plan, it is recommended to consult with a qualified Ayurvedic practitioner who can assess your specific condition and prescribe the most appropriate remedies.\n> \n> May the ancient wisdom of Ayurveda guide you towards healing and well-being.\n> \n> **Note:** Always consult with a qualified healthcare professional before using any herbal remedies or supplements."
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nWMcLBgdtPST"
      }
    }
  ]
}